{"meta":{"title":"Knowledge Has NO Limit","subtitle":null,"description":null,"author":"Chern Tau","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"One Day Traveling in Yinxing Lake","slug":"I-love-Xumengyue","date":"2017-08-15T14:47:34.000Z","updated":"2017-09-24T05:15:46.262Z","comments":true,"path":"2017/08/15/I-love-Xumengyue/","link":"","permalink":"http://yoursite.com/2017/08/15/I-love-Xumengyue/","excerpt":"","text":"One Day Traveling in Yinxing Lake","categories":[],"tags":[]},{"title":"Web crawling CSI 300 index using Python","slug":"Web crawling CSI 300 index using Python","date":"2017-08-08T04:48:03.000Z","updated":"2017-08-08T12:54:17.000Z","comments":true,"path":"2017/08/08/Web crawling CSI 300 index using Python/","link":"","permalink":"http://yoursite.com/2017/08/08/Web crawling CSI 300 index using Python/","excerpt":"","text":"Simulating browser loginYou must make sure that you have installed firefox browser. 123456789from selenium import webdriverfrom selenium.webdriver.common.keys import Keysimport timeimport pandas as pdimport reimport numpy as npfrom bs4 import BeautifulSoupdriver = webdriver.Firefox() Finding the CSI 300 index url in Google Finance1234567891011121314151617181920212223242526272829303132333435363738394041var = [&apos;Date&apos;, &apos;Open&apos;, &apos;High&apos;, &apos;Low&apos;, &apos;Close&apos;, &apos;Volume&apos;]csi = &#123;&#125;for j in range(0,29): urll = &quot;https://www.google.com/finance/historical?cid=1979150&amp;startdate=Jan%201%2C%202014&amp;enddate=Jul%2010%2C%202017&amp;num=30&amp;ei=BxBkWdGLK5DijAHogaDwCg&quot;+&quot;&amp;start=%s&quot; % (j*30) driver.get(urll) html = BeautifulSoup(driver.page_source,&apos;lxml&apos;) info = html.find_all(&apos;table&apos;, class_=&quot;gf-table historical_price&quot;) info1 = info[0] info3 = info1.find_all(&quot;td&quot;) for i in range(len(info3)-1): if i % 6 == 0: valuetag = info3[i] value = valuetag.string value = value.replace(&quot;\\n&quot;,&quot;&quot;) csi.setdefault(var[0],[]).append(value) elif i % 6 == 1: valuetag = info3[i] value = valuetag.string value = value.replace(&quot;\\n&quot;,&quot;&quot;) csi.setdefault(var[1],[]).append(value) elif i % 6 == 2: valuetag = info3[i] value = valuetag.string value = value.replace(&quot;\\n&quot;,&quot;&quot;) csi.setdefault(var[2],[]).append(value) elif i % 6 == 3: valuetag = info3[i] value = valuetag.string value = value.replace(&quot;\\n&quot;,&quot;&quot;) csi.setdefault(var[3],[]).append(value) elif i % 6 == 4: valuetag = info3[i] value = valuetag.string value = value.replace(&quot;\\n&quot;,&quot;&quot;) csi.setdefault(var[4],[]).append(value) else: valuetag = info3[i] value = valuetag.string value = value.replace(&quot;\\n&quot;,&quot;&quot;) csi.setdefault(var[5],[]).append(value) Writing file in local folder1234data = pd.DataFrame.from_dict(csi,orient=&apos;index&apos;).Tdata.to_csv(&apos;data.csv&apos;,header = True,encoding=&quot;utf_8_sig&quot;)","categories":[],"tags":[]},{"title":"Install R and RStudio in Ubuntu","slug":"Install-R-and-RStudio-in-Ubuntu","date":"2017-08-07T04:48:03.000Z","updated":"2017-08-08T12:53:49.000Z","comments":true,"path":"2017/08/07/Install-R-and-RStudio-in-Ubuntu/","link":"","permalink":"http://yoursite.com/2017/08/07/Install-R-and-RStudio-in-Ubuntu/","excerpt":"","text":"Install RAdd Mirror source12sudo gedit /etc/apt/sources.listdeb http://cran.rstudio.com/bin/linux/ubuntu trusty/ # Add the code in the end of sources.list Run command of downloading public key12sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 51716619E084DAB9sudo apt-get update # Update Install R12sudo apt-get install r-baseR # Verify whether it succeed Install RStudioVisit http://www.rstudio.com/products/rstudio/download/ download related file Input code in Terminal123sudo apt-get install gdebi-coresudo apt-get install libapparmor1 # Required only for Ubuntu, not Debiansudo gdebi * # Downloaded RStudio*.deb file","categories":[],"tags":[]},{"title":"Install Hadoop on Ubuntu","slug":"Install Hadoop on Ubuntu","date":"2017-08-07T04:48:03.000Z","updated":"2017-08-08T12:54:04.000Z","comments":true,"path":"2017/08/07/Install Hadoop on Ubuntu/","link":"","permalink":"http://yoursite.com/2017/08/07/Install Hadoop on Ubuntu/","excerpt":"","text":"Install JDKVisit http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html and download jre-8u121-linux-x64.tar.gz file to Home. Open terminal, get root and create new folder on the home1234sudo passwd root # set root passwordsu # get rootgedit /etc/sudoers # add chan ALL(ALL) ALL to behind root linesudo mkdir hadoop # create new folder Copy jre-8u121-linux-x64.tar.gz file to hadoop folder1cp jre-8u121-linux-x64.tar.gz /home/chan/hadoop # chan is user name Explode jre-8u121-linux-x64.tar.gz file123cd home/chan/hadooptar -zxvf jre-8u121-linux-x64.tar.gz # exploderm jre-8u121-linux-x64.tar.gz # delete Set JDK environment variable1sudo gedit /etc/profile Add codes at the end of profile123export JAVA_HOME=/home/name(user)/hadoop/jre1.8.0_121 # the name of the JDK folderexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar Check12source /etc/profile # make JDK effectivejava -version # showing java version &quot;xxxx&quot;, it succeed Configure hosts fileRevise hostname123sugedit etc/hostname # revise hostname to &quot;master&quot; and input slave1, slave2 in othersreboot Check IP address1ifconfig # copy IP address Configure host12sugedit /etc/hosts #paste IP address and input &quot;master&quot;, &quot;slave1&quot;, &quot;slave2&quot; Copy configured host to slaves12scp /etc/hosts root@slave1:/etc/scp /etc/hosts root@slave2:/etc/ 2.5 Check slavers whether connected 12ping slave1 # must input in masterping slave2 SSH login without passwordTurn off firewall123susysv-rc-conf iptables off # need install sys-rc-confreboot Configure SSH in master123456ssh-keygen -t rsa # press ENTERcd .sshcat id_rsa.pub &gt;&gt; authorized_keyschmod 600 authorized_keysscp authorized_keys chan@slave1:~/.ssh/scp authorized_keys chan(user)@slave2:~/.ssh/ Check for success123ssh slave1ssh slave2shh master Install and configure Hadoop in masterVisit http://apache.fayea.com/hadoop/common/ and download hadoop-2.6.4.tar.gz Copy hadoop-2.6.4.tar.gz to hadoop folder12cd hadooptar -zxvf hadoop-2.6.4.tar.gz Configure files of HadoopConfigure hadoop-env.sh12345cd hadoop/hadoop-2.6.4cd etc/hadoopgedit hadoop-env.sh# add this code at end of hadoop-env.shexport JAVA_HOME=/home/chan/hadoop/jre1.8.0_121 Configure core-site.xml12345678910111213141516gedit core-site.xml# add this code between configuration&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/chan/hadoop/tmp&lt;/value&gt; # user name&lt;/property&gt;&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:54310&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt; Configure hdfs-site.xml12345678910111213141516gedit hdfs-site.xml# add this code between configuration&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;file:/home/chan/hadoop/dfs/name&lt;/value&gt; # user name &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/chan/hadoop/dfs/data&lt;/value&gt; #user name &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt;&lt;/property&gt; Configure mapred-site.xml12345678910111213141516mv mapred-site.xml.template mapred-site.xml # renamegedit mapred-site.xml# add this code between configuration&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt;&lt;/property&gt; Configure yarn-site.xml123456789101112131415161718192021222324252627282930gedit yarn-site.xml# add this code between configuration&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-serivces.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;master:8033&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt;&lt;/property&gt; Configure master123gedit master#add this codemaster Configure slaves12345gedit slaves#add this codemasterslave1slave2 Copy configured files to slaves1234cdcd hadoopscp -r hadoop-2.6.4 slave1:~/hadoopscp -r hadoop-2.6.4 slave2:~/hadoop Start cluster1234cdcd hadoop/hadoop-2.6.4bin/hdfs namenode -format # format namenodesbin/start-all.sh Check cluster1jps # maybe need install","categories":[],"tags":[]}]}